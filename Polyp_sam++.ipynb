{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-09T06:15:18.774728076Z",
     "start_time": "2023-10-09T06:09:00.269887535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/ai-38/anaconda3/envs/tfgpu/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\r\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-p7z3wnnm\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-p7z3wnnm\r\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[?25h/bin/bash: /home/ai-38/anaconda3/envs/tfgpu/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "/bin/bash: /home/ai-38/anaconda3/envs/tfgpu/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting datasets\r\n",
      "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m519.6/519.6 kB\u001B[0m \u001B[31m200.6 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m[36m0:00:01\u001B[0mm eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\r\n",
      "Requirement already satisfied: pandas in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from datasets) (2.1.1)\r\n",
      "Collecting multiprocess\r\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m111.8 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m109.9 kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting fsspec[http]<2023.9.0,>=2023.1.0\r\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m163.8/163.8 kB\u001B[0m \u001B[31m188.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m181.8 kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from datasets) (1.25.2)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from datasets) (4.66.1)\r\n",
      "Requirement already satisfied: aiohttp in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from datasets) (3.8.5)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from datasets) (0.17.3)\r\n",
      "Collecting pyarrow>=8.0.0\r\n",
      "  Downloading pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.0/40.0 MB\u001B[0m \u001B[31m249.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m[36m0:00:05\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: packaging in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from datasets) (23.1)\r\n",
      "Collecting xxhash\r\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m441.3 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting dill<0.3.8,>=0.3.0\r\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.3/115.3 kB\u001B[0m \u001B[31m579.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m kB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.25.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from aiohttp->datasets) (3.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\r\n",
      "Requirement already satisfied: filelock in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.3)\r\n",
      "Installing collected packages: xxhash, pyarrow, fsspec, dill, multiprocess, datasets\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2023.9.2\r\n",
      "    Uninstalling fsspec-2023.9.2:\r\n",
      "      Successfully uninstalled fsspec-2023.9.2\r\n",
      "Successfully installed datasets-2.14.5 dill-0.3.7 fsspec-2023.6.0 multiprocess-0.70.15 pyarrow-13.0.0 xxhash-3.4.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "/bin/bash: /home/ai-38/anaconda3/envs/tfgpu/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "/bin/bash: /home/ai-38/anaconda3/envs/tfgpu/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting patchify\r\n",
      "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ai-38/PycharmProjects/pythonProject/venv/lib/python3.10/site-packages (from patchify) (1.25.2)\r\n",
      "Installing collected packages: patchify\r\n",
      "Successfully installed patchify-0.2.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install the required libraries\n",
    "#SAM\n",
    "# !pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "# #Transformers\n",
    "# !pip install -q git+https://github.com/huggingface/transformers.git\n",
    "# #Datasets to prepare data and monai if you want to use special loss functions\n",
    "# !pip install datasets\n",
    "# !pip install -q monai\n",
    "# #Patchify to divide large images into smaller patches for training. (Not necessary for smaller images)\n",
    "# !pip install patchify\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tifffile\n",
    "# import os\n",
    "# from patchify import patchify  #Only to handle large images\n",
    "# import random\n",
    "# from scipy import ndimage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafead2a68d00518"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install -U git+https://github.com/luca-medeiros/lang-segment-anything.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "674106bb0f333eb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from lang_sam import LangSAM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d009c235f7a25ecf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = '/home/ai-38/POLYPDATA/CVC-300/images/CVC-300_039.png'\n",
    "\n",
    "text_prompt = \"\"\"\n",
    "A polyp is an anomalous ovalshaped small bump-like structure, a relatively small growth or\n",
    "mass that develops on the inner lining of the colon or other organs.\n",
    "Multiple polyps may exist in one image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "def save_mask(mask_np, filename):\n",
    "    mask_image = Image.fromarray((mask_np * 255).astype(np.uint8))\n",
    "    mask_image.save(filename)\n",
    "\n",
    "def display_image_with_masks(image, masks):\n",
    "    num_masks = len(masks)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_masks + 1, figsize=(15, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i, mask_np in enumerate(masks):\n",
    "        axes[i+1].imshow(mask_np, cmap='gray')\n",
    "        axes[i+1].set_title(f\"Mask {i+1}\")\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_image_with_boxes(image, boxes, logits):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(\"Image with Bounding Boxes\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    for box, logit in zip(boxes, logits):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        confidence_score = round(logit.item(), 2)  # Convert logit to a scalar before rounding\n",
    "        box_width = x_max - x_min\n",
    "        box_height = y_max - y_min\n",
    "\n",
    "        # Draw bounding box\n",
    "        rect = plt.Rectangle((x_min, y_min), box_width, box_height, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add confidence score as text\n",
    "        ax.text(x_min, y_min, f\"Confidence: {confidence_score}\", fontsize=8, color='red', verticalalignment='top')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def print_bounding_boxes(boxes):\n",
    "    print(\"Bounding Boxes:\")\n",
    "    for i, box in enumerate(boxes):\n",
    "        print(f\"Box {i+1}: {box}\")\n",
    "\n",
    "def print_detected_phrases(phrases):\n",
    "    print(\"\\nDetected Phrases:\")\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        print(f\"Phrase {i+1}: {phrase}\")\n",
    "\n",
    "def print_logits(logits):\n",
    "    print(\"\\nConfidence:\")\n",
    "    for i, logit in enumerate(logits):\n",
    "        print(f\"Logit {i+1}: {logit}\")\n",
    "\n",
    "def main():\n",
    "    # Suppress warning messages\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    try:\n",
    "        if image.startswith(\"http\"):\n",
    "            image_pil = download_image(image)\n",
    "        else:\n",
    "            image_pil = Image.open(image).convert(\"RGB\")\n",
    "\n",
    "        model = LangSAM()\n",
    "        masks, boxes, phrases, logits = model.predict(image_pil, text_prompt)\n",
    "\n",
    "        if len(masks) == 0:\n",
    "            print(f\"No objects of the '{text_prompt}' prompt detected in the image.\")\n",
    "        else:\n",
    "            # Convert masks to numpy arrays\n",
    "            masks_np = [mask.squeeze().cpu().numpy() for mask in masks]\n",
    "\n",
    "            # Display the original image and masks side by side\n",
    "            display_image_with_masks(image_pil, masks_np)\n",
    "\n",
    "            # Display the image with bounding boxes and confidence scores\n",
    "            display_image_with_boxes(image_pil, boxes, logits)\n",
    "\n",
    "            # Save the masks\n",
    "            for i, mask_np in enumerate(masks_np):\n",
    "                mask_path = f\"image_mask_{i+1}.png\"\n",
    "                save_mask(mask_np, mask_path)\n",
    "\n",
    "            # Print the bounding boxes, phrases, and logits\n",
    "            print_bounding_boxes(boxes)\n",
    "            print_detected_phrases(phrases)\n",
    "            print_logits(logits)\n",
    "\n",
    "    except (requests.exceptions.RequestException, IOError) as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463687cb5ebbd5b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "from lang_sam import LangSAM\n",
    "# (import your actual LangSAM class if it's located in a different module)\n",
    "\n",
    "# The path to the folder containing images\n",
    "image_folder = \"/home/ai-38/POLYPDATA/CVC-300/images\"\n",
    "\n",
    "text_prompt = \"\"\"A polyp is an anomalous oval shaped small bump like structure, relatively small growth or mass that develops on the inner lining of the colon or other organs.\n",
    "Multiple ployps may exist in one image\n",
    "\"\"\"\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "def save_mask(mask_np, filename):\n",
    "    mask_image = Image.fromarray((mask_np * 255).astype(np.uint8))\n",
    "    mask_image.save(filename)\n",
    "\n",
    "def display_image_with_masks(image, masks):\n",
    "    num_masks = len(masks)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_masks + 1, figsize=(15, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i, mask_np in enumerate(masks):\n",
    "        axes[i+1].imshow(mask_np, cmap='gray')\n",
    "        axes[i+1].set_title(f\"Mask {i+1}\")\n",
    "        axes[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_image_with_boxes(image, boxes, logits):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(\"Image with Bounding Boxes\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    for box, logit in zip(boxes, logits):\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        confidence_score = round(logit.item(), 2)  # Convert logit to a scalar before rounding\n",
    "        box_width = x_max - x_min\n",
    "        box_height = y_max - y_min\n",
    "\n",
    "        # Draw bounding box\n",
    "        rect = plt.Rectangle((x_min, y_min), box_width, box_height, fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add confidence score as text\n",
    "        ax.text(x_min, y_min, f\"Confidence: {confidence_score}\", fontsize=8, color='red', verticalalignment='top')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def print_bounding_boxes(boxes):\n",
    "    print(\"Bounding Boxes:\")\n",
    "    for i, box in enumerate(boxes):\n",
    "        print(f\"Box {i+1}: {box}\")\n",
    "\n",
    "def print_detected_phrases(phrases):\n",
    "    print(\"\\nDetected Phrases:\")\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        print(f\"Phrase {i+1}: {phrase}\")\n",
    "\n",
    "def print_logits(logits):\n",
    "    print(\"\\nConfidence:\")\n",
    "    for i, logit in enumerate(logits):\n",
    "        print(f\"Logit {i+1}: {logit}\")\n",
    "\n",
    "def save_mask(mask_np, filename):\n",
    "    mask_image = Image.fromarray((mask_np * 255).astype(np.uint8))\n",
    "    mask_image.save(filename)\n",
    "\n",
    "def main():\n",
    "    # Suppress warning messages\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Create a folder for saving masks if it doesn't exist\n",
    "    if not os.path.exists(\"Combined_mask_output\"):\n",
    "        os.makedirs(\"Combined_mask_output\")\n",
    "\n",
    "    try:\n",
    "        # Get a list of image files in the folder\n",
    "        image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(\".png\")]\n",
    "\n",
    "        if len(image_files) == 0:\n",
    "            print(\"No PNG images found in the specified folder.\")\n",
    "            return\n",
    "\n",
    "        model = LangSAM()\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "            masks, boxes, phrases, logits = model.predict(image_pil, text_prompt)\n",
    "\n",
    "            if len(masks) == 0:\n",
    "                print(f\"No objects of the '{text_prompt}' prompt detected in {image_file}.\")\n",
    "            else:\n",
    "                # Convert masks to numpy arrays\n",
    "                masks_np = [mask.squeeze().cpu().numpy() for mask in masks]\n",
    "\n",
    "                # Display the original image and masks side by side\n",
    "                display_image_with_masks(image_pil, masks_np)\n",
    "\n",
    "                # Display the image with bounding boxes and confidence scores\n",
    "                display_image_with_boxes(image_pil, boxes, logits)\n",
    "\n",
    "                # Save the masks\n",
    "                for i, mask_np in enumerate(masks_np):\n",
    "                    mask_filename = f\"Combined_mask_output/{image_file}\"\n",
    "                    save_mask(mask_np, mask_filename)\n",
    "\n",
    "                # Print the bounding boxes, phrases, and logits\n",
    "                print_bounding_boxes(boxes)\n",
    "                print_detected_phrases(phrases)\n",
    "                print_logits(logits)\n",
    "\n",
    "    except (requests.exceptions.RequestException, IOError) as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2ef652d82680248"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cddc7d7a87ac8ccf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "75218802c6e30e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b9d1e88affdc15c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6e4cb2c4a7ea0df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a6d1721c4189b43c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
